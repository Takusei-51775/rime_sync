{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import opencc\n",
    "\n",
    "from pypinyin import pinyin, lazy_pinyin, Style\n",
    "import os\n",
    "\n",
    "import tqdm\n",
    "from pyscripts.words import *\n",
    "\n",
    "cc = opencc.OpenCC(\"s2t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Dict\n",
    "### Based on udpn_weight.dict.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD CHARACTER DICT \n",
    "\n",
    "# import tqdm\n",
    "\n",
    "# filename = \"./dicts/udpn/udpn_weight.dict.yaml\"\n",
    "\n",
    "# char2scode = {}\n",
    "# line_num_dict = {}\n",
    "# chardict = {} \n",
    "\n",
    "\n",
    "# with open(filename, \"r\", encoding=\"UTF-8\") as infile:\n",
    "#     for i, line in tqdm.tqdm(enumerate(infile.readlines())):\n",
    "#         if '#' in line or not '[' in line:\n",
    "#             continue\n",
    "#         char = cc.convert(line.split()[0])\n",
    "#         pron = line.split()[1][:2]\n",
    "#         code = line.split()[1][3:]\n",
    "\n",
    "#         if char not in line_num_dict:\n",
    "#             line_num_dict[char] = [i + 1]\n",
    "#         else:\n",
    "#             line_num_dict[char].append(i + 1)\n",
    "        \n",
    "#         if char in char2scode.keys() and char2scode[char] != code:\n",
    "#             if char2scode[char] == \"[\":\n",
    "#                 char2scode[char] = code\n",
    "#             elif code == \"[\":\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 print(f\"Lines {','.join(str(x) for x in line_num_dict[char])}: {char} has codes {char2scode[char]} and {code}\")\n",
    "#             # print(f\"Lines {','.join(str(x) for x in line_num_dict[char])}: {char} has codes {char_dict[char]} and {code}\")\n",
    "#         else:\n",
    "#             char2scode[char] = code\n",
    "\n",
    "#     char2scode[\"乾\"] = \"ur\"\n",
    "\n",
    "#     # write full line dict in a 2nd iter, keeping correct codes\n",
    "\n",
    "# with open(filename, \"r\", encoding=\"UTF-8\") as infile:\n",
    "#     for i, line in tqdm.tqdm(enumerate(infile.readlines())):\n",
    "#         if '#' in line or not '[' in line:\n",
    "#             continue\n",
    "\n",
    "#         char = cc.convert(line.split()[0])\n",
    "#         pron = line.split()[1][:2]\n",
    "#         weight = int(line.split()[2]) # Load already weighted dict\n",
    "        \n",
    "#         chardict[(char, pron)] = [char2scode[char], weight]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45951it [00:00, 180459.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines 27051,45950: 鍾 has codes jv and jp\n",
      "Lines 28929,45951: 鮎 has codes yb and yr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45951it [00:00, 158175.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# LOAD CHARACTER DICT \n",
    "\n",
    "filename = \"./dicts/udpn/udpn_weight.dict.yaml\"\n",
    "\n",
    "char2scode = {}\n",
    "line_num_dict = {}\n",
    "\n",
    "chardict = CharDict()\n",
    "\n",
    "\n",
    "with open(filename, \"r\", encoding=\"UTF-8\") as infile:\n",
    "    for i, line in tqdm.tqdm(enumerate(infile.readlines())):\n",
    "        if '#' in line or not '[' in line:\n",
    "            continue\n",
    "        char = cc.convert(line.split()[0])\n",
    "        pron = line.split()[1][:2]\n",
    "        code = line.split()[1][3:]\n",
    "\n",
    "        if char not in line_num_dict:\n",
    "            line_num_dict[char] = [i + 1]\n",
    "        else:\n",
    "            line_num_dict[char].append(i + 1)\n",
    "        \n",
    "        if char in char2scode.keys() and char2scode[char] != code:\n",
    "            if char2scode[char] == \"[\":\n",
    "                char2scode[char] = code\n",
    "            elif code == \"[\":\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"Lines {','.join(str(x) for x in line_num_dict[char])}: {char} has codes {char2scode[char]} and {code}\")\n",
    "            # print(f\"Lines {','.join(str(x) for x in line_num_dict[char])}: {char} has codes {char_dict[char]} and {code}\")\n",
    "        else:\n",
    "            char2scode[char] = code\n",
    "\n",
    "    char2scode[\"乾\"] = \"ur\"\n",
    "\n",
    "    # write full line dict in a 2nd iter, keeping correct codes\n",
    "\n",
    "with open(filename, \"r\", encoding=\"UTF-8\") as infile:\n",
    "    for i, line in tqdm.tqdm(enumerate(infile.readlines())):\n",
    "        if '#' in line or not '[' in line:\n",
    "            continue\n",
    "\n",
    "        char = cc.convert(line.split()[0])\n",
    "        pron = line.split()[1][:2]\n",
    "        weight = int(line.split()[2]) # Load already weighted dict\n",
    "\n",
    "        \n",
    "        if char not in chardict:\n",
    "            chardict[char] = []\n",
    "\n",
    "        chardict[char].append(CharInfo(pron, char2scode[char], weight))\n",
    "\n",
    "chardict.SortWeight()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qm ur 67122\n",
      "gj ur 0\n",
      "煙燻\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(*chardict[\"乾\"], sep='\\n')\n",
    "print(cc.convert(\"烟熏\"))\n",
    "\n",
    "\n",
    "# 乾 has codes hu and ur\n",
    "# 谘\tzi[yd\n",
    "# 薰 has codes pd and cp\n",
    "# 锺\tvs[jp\n",
    "# 鲶\tnm[yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def qp2udpn(char):\n",
    "    assert(len(char.split()) == 1)\n",
    "\n",
    "    char = re.sub(r\"sh\", r\"U\", char)\n",
    "    char = re.sub(r\"ch\", r\"I\", char)\n",
    "    char = re.sub(r\"zh\", r\"V\", char)\n",
    "    \n",
    "    char = re.sub(r\"(\\w)[iu]ang\\b\", r\"\\1D\", char)\n",
    "    char = re.sub(r\"(\\w)i?ong\\b\", r\"\\1S\", char)\n",
    "    char = re.sub(r\"(\\w)iao\\b\", r\"\\1C\", char)\n",
    "    char = re.sub(r\"(\\w)ian\\b\", r\"\\1M\", char)\n",
    "    char = re.sub(r\"(\\w)eng\\b\", r\"\\1G\", char)\n",
    "    char = re.sub(r\"(\\w)ang\\b\", r\"\\1H\", char)\n",
    "    char = re.sub(r\"(\\w)ing\\b\", r\"\\1;\", char)\n",
    "    char = re.sub(r\"(\\w)uan\\b\", r\"\\1R\", char)\n",
    "    char = re.sub(r\"(\\w)uai\\b\", r\"\\1Y\", char)\n",
    "    char = re.sub(r\"(\\w)iu\\b\", r\"\\1Q\", char)\n",
    "    char = re.sub(r\"(\\w)er\\b\", r\"\\1R\", char)\n",
    "    char = re.sub(r\"(\\w)uo\\b\", r\"\\1O\", char)\n",
    "    char = re.sub(r\"(\\w)un\\b\", r\"\\1P\", char)\n",
    "    char = re.sub(r\"(\\w)en\\b\", r\"\\1F\", char)\n",
    "    char = re.sub(r\"(\\w)an\\b\", r\"\\1J\", char)\n",
    "    char = re.sub(r\"(\\w)ao\\b\", r\"\\1K\", char)\n",
    "    char = re.sub(r\"(\\w)ai\\b\", r\"\\1L\", char)\n",
    "    char = re.sub(r\"(\\w)ei\\b\", r\"\\1Z\", char)\n",
    "    char = re.sub(r\"(\\w)ie\\b\", r\"\\1X\", char)\n",
    "    char = re.sub(r\"(\\w)ui\\b\", r\"\\1V\", char)\n",
    "    char = re.sub(r\"(\\w)ou\\b\", r\"\\1B\", char)\n",
    "    char = re.sub(r\"(\\w)in\\b\", r\"\\1N\", char)\n",
    "    char = re.sub(r\"(\\w)v\\b\", r\"\\1Y\", char)\n",
    "    char = re.sub(r\"(\\w)[iu]a\\b\", r\"\\1W\", char)\n",
    "    char = re.sub(r\"(\\w)[uv]e\\b\", r\"\\1T\", char)\n",
    "\n",
    "    char = re.sub(r\"(\\b)ai\\b\", r\"OL\", char)\n",
    "    char = re.sub(r\"(\\b)an\\b\", r\"OJ\", char)\n",
    "    char = re.sub(r\"(\\b)ang\\b\", r\"OH\", char)\n",
    "    char = re.sub(r\"(\\b)ao\\b\", r\"OK\", char)\n",
    "    char = re.sub(r\"(\\b)ei\\b\", r\"OZ\", char)\n",
    "    char = re.sub(r\"(\\b)en\\b\", r\"OF\", char)\n",
    "    char = re.sub(r\"(\\b)er\\b\", r\"OR\", char)\n",
    "    char = re.sub(r\"(\\b)ou\\b\", r\"OB\", char)\n",
    "    char = re.sub(r\"(\\b)eng\\b\", r\"OG\", char)\n",
    "\n",
    "    # char = re.sub(r\"(\\w)a\", r\"\\1A\", char)\n",
    "    # char = re.sub(r\"(\\w)E\", r\"\\1E\", char)\n",
    "    # char = re.sub(r\"(\\w)O\", r\"\\1O\", char)\n",
    "\n",
    "    char = re.sub(r\"(\\b)a\\b\", r\"OA\", char)\n",
    "    char = re.sub(r\"(\\b)e\\b\", r\"OE\", char)\n",
    "    char = re.sub(r\"(\\b)o\\b\", r\"OO\", char)\n",
    "\n",
    "    return char.lower()\n",
    "\n",
    "\n",
    "def qp2udpn_code(word, quanpin):\n",
    "    word = cc.convert(word)\n",
    "    codes = []\n",
    "    for i, char in enumerate(quanpin.split()):\n",
    "        udpn = qp2udpn(char)        \n",
    "        codes.append(udpn + '[' + char2scode[word[i]])\n",
    "    \n",
    "    return ' '.join(codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qm[sq\n",
      "vy[fo bm[yy\n"
     ]
    }
   ],
   "source": [
    "print(qp2udpn_code(\"纤\", \"qian\"))\n",
    "print(qp2udpn_code(\"拽变\", \"zhuai bian\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [00:00<00:00, 8408.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert dict\n",
    "\n",
    "\n",
    "src_dict = \"./dicts/emoji.dict.yaml\"\n",
    "\n",
    "with open(src_dict, \"r\", encoding=\"UTF-8\") as infile:\n",
    "    with open(os.path.join(\"./dicts/udpn/\", \"udpn_\" + os.path.basename(src_dict)), \"w\", encoding=\"UTF-8\") as outfile:\n",
    "        for line in tqdm.tqdm(infile.readlines()):\n",
    "            if '\\t' not in line:\n",
    "                outfile.writelines(line)\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    components = line.split('\\t')\n",
    "                    components[0] = cc.convert(components[0])\n",
    "                    components[1] = qp2udpn_code(components[0], components[1])\n",
    "                    newline = '\\t'.join(components)\n",
    "                    if '\\n' not in newline: \n",
    "                        newline += '\\n'\n",
    "                    outfile.writelines(newline)\n",
    "                except:\n",
    "                    print(line)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8579/8579 [00:00<00:00, 24440.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# weight\n",
    "\n",
    "\n",
    "weight_dict = \"./dicts/simp_for_udpn_weight.dict.yaml\"\n",
    "\n",
    "with open(weight_dict, \"r\", encoding=\"UTF-8\") as infile:\n",
    "    with open(\"./dicts/udpn/not_found.txt\", \"w\", encoding=\"UTF-8\") as outfile:\n",
    "        for line in tqdm.tqdm(infile.readlines()):\n",
    "                if '#' not in line and '\\t' in line:\n",
    "                    # try:\n",
    "                    components = line.split()\n",
    "                    char = cc.convert(components[0])\n",
    "                    pron = qp2udpn(components[1])\n",
    "                    freq = components[2]\n",
    "\n",
    "                    if (char, pron) not in chardict:\n",
    "                        if char in char2scode:\n",
    "                            chardict[(char, pron)] = [char2scode[char], freq]\n",
    "                        else:\n",
    "                            chardict[(char, pron)] = ['[', freq]\n",
    "                            # outfile.writelines(line)\n",
    "                            # print(\" \".join([char, pron, freq]))\n",
    "                    else:\n",
    "                        chardict[(char, pron)][1] = freq\n",
    "                    # except:\n",
    "                    #     print(line)\n",
    "\n",
    "# specials:              \n",
    "    chardict[(\"锺\", \"vs\")] = [\"jp\", 1] # 锺\tvs[jp\n",
    "    chardict[(\"鲶\", \"nm\")] = [\"yr\", 1] # 鲶\tnm[yr\n",
    "\n",
    "with open(\"./dicts/udpn/udpn_weight.dict.yaml\", \"w\", encoding=\"UTF-8\") as outfile:\n",
    "    for key,value in chardict.items():\n",
    "        everything = [key[0], key[1] + '[' + value[0], str(value[1])]\n",
    "        if len(value) == 3: everything.append(value[2])\n",
    "        outline = '\\t'.join(everything) + '\\n'\n",
    "        outfile.writelines(outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 205931/5987612 [00:26<11:53, 8101.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本驹込 本駒込 本駒込 ben ju yu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 587930/5987612 [01:13<11:37, 7736.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "驹込站 駒込站 駒込站 ju yu zhan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 3363551/5987612 [08:18<07:18, 5982.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "込山榛香 込山榛香 込山榛香 yu shan zhen xiang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 3712166/5987612 [09:18<05:42, 6648.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# superime convert\n",
    "\n",
    "with open(\"./out.dict.yaml\", \"r\", encoding=\"UTF-8\") as infile:\n",
    "    with open(os.path.join(\"./dicts/udpn/\", \"udpn_superime.dict.yaml\"), \"w\", encoding=\"UTF-8\") as outfile:\n",
    "        for i, line in enumerate(tqdm.tqdm(infile.readlines())):\n",
    "                components = line.split('\\t')\n",
    "                word = components[0]\n",
    "                pron = components[1]\n",
    "                if len(word) >= 5:\n",
    "                    break\n",
    "                if \"什么\" in word and \"shi mo\" in pron:\n",
    "                    pron = pron.replace(\"shi mo\", \"shen me\")\n",
    "                \n",
    "                try:\n",
    "                    new_word = cc.convert(word)\n",
    "                    udpn_code = qp2udpn_code(new_word, pron)\n",
    "                except:\n",
    "                    try:\n",
    "                        char_by_char = ''.join([cc.convert(x) for x in new_word])\n",
    "                        udpn_code = qp2udpn_code(char_by_char, pron)\n",
    "                    except:\n",
    "                        print(word, new_word, char_by_char, pron)\n",
    "                        continue\n",
    "                        # break\n",
    "\n",
    "                newline = '\\t'.join([new_word, udpn_code])\n",
    "                if '\\n' not in newline: \n",
    "                    newline += '\\n'\n",
    "                outfile.writelines(newline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鍾小云\n",
      "cx\n",
      "['cx', 186450]\n",
      "新北里\n",
      "裏\n",
      "云云\n"
     ]
    }
   ],
   "source": [
    "print(cc.convert(\"钟小云\"))\n",
    "\n",
    "print(char2scode[\"慕\"])\n",
    "print(chardict[('慕', 'mu')])\n",
    "print(cc.convert(\"新北里\"))\n",
    "print(cc.convert(\"里\"))\n",
    "print(cc.convert(\"云云\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting superime (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3712094 [00:00<?, ?it/s]C:\\Users\\Takusei\\AppData\\Local\\Temp\\ipykernel_9932\\3664338310.py:19: RuntimeWarning: divide by zero encountered in log10\n",
      "  total_weight += weight_factor[j] * np.log10(line_dict[(char, pron)][1])\n",
      "  0%|          | 10000/3712094 [00:00<01:09, 52909.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('是與有\\tui[op yu[hv yb[uo\\n', 11.569661225247058), ('是因爲\\tui[op yn[wd wz[dl\\n', 11.466871429077155), ('是與真\\tui[op yu[hv vf[uj\\n', 11.35032935187564), ('你愛我\\tni[rd ol[au wo[pf\\n', 11.248454572054456), ('是與非\\tui[op yu[hv fz[su\\n', 11.220039907921816)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ordered_superime = {}\n",
    "\n",
    "with open(os.path.join(\"./dicts/udpn/\", \"udpn_superime.dict.yaml\"), \"r\", encoding=\"UTF-8\") as infile:\n",
    "    for i, line in enumerate(tqdm.tqdm(infile.readlines())):\n",
    "        if '\\t' not in line:\n",
    "            continue\n",
    "        components = line.split('\\t')\n",
    "        word = components[0]\n",
    "        prons = components[1].split()\n",
    "        assert len(word) == len(prons), f\"???? {line}\"\n",
    "        \n",
    "        total_weight = 0\n",
    "        weight_factor = [1, 0.3, 0.3]\n",
    "        for j in range(len(word)):\n",
    "            char = cc.convert(word[j])\n",
    "            pron = prons[j][:2]\n",
    "            total_weight += weight_factor[j] * np.log10(chardict[(char, pron)][1])\n",
    "        ordered_superime[line] = total_weight\n",
    "    \n",
    "        if i >= 10000: \n",
    "            break\n",
    "\n",
    "# print(list(ordered_superime.items())[0:5])\n",
    "ordered_superime = sorted(ordered_superime.items(), key = lambda x: (x[1], x[0]), reverse=True)\n",
    "print(ordered_superime[0:5])\n",
    "\n",
    "with open(os.path.join(\"./dicts/udpn/\", \"superime_weight.dict.yaml\"), \"w\", encoding=\"UTF-8\") as outfile:\n",
    "    for (line, weight) in ordered_superime:\n",
    "        line = line.split('\\n')[0] + '\\t' + str(weight) + '\\n'\n",
    "        outfile.writelines(line)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dicts (yaml re-editing, txt...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "def MakeWord(word, prons = None, weight = None):\n",
    "    charinfos = [CharInfo(chardict[char][0]) for char in word]\n",
    "    return WordInfo(word, charinfos, prons, weight)\n",
    "\n",
    "class DictType(Enum):\n",
    "    UDPN_SCODE = 0\n",
    "    QUANPIN = 1\n",
    "    WORDS_ONLY = 2\n",
    "\n",
    "wordsdict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 19087.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch: 把刀, ba dk with ba dl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# filename = \"./dicts/udpn/udpn_simp-ext.dict.yaml\"\n",
    "filename = \"./dicts/udpn/udpn_test.dict.yaml\"\n",
    "filetype = DictType.UDPN_SCODE\n",
    "\n",
    "with open(filename, \"r\", encoding=\"UTF-8\") as infile:\n",
    "    for i, line in tqdm.tqdm(enumerate(infile.readlines())):\n",
    "        if filetype == DictType.UDPN_SCODE:\n",
    "            if '#' in line or not '[' in line:\n",
    "                continue\n",
    "            components = line.split('\\t')\n",
    "            word = cc.convert(components[0])\n",
    "            prons_scode = components[1]\n",
    "            weight = components[2]\n",
    "            \n",
    "            prons = [x[:2] for x in prons_scode.split()]\n",
    "            \n",
    "            if word in wordsdict:\n",
    "                for i in range(len(word)):\n",
    "                    if wordsdict[word].chars[i].pron != prons[i]:\n",
    "                        print(f\"Mismatch: {word}, {' '.join(wordsdict[word].GetPron())} with {' '.join(prons)}\")\n",
    "            else:\n",
    "                wordsdict[word] = MakeWord(word, prons, weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'吃'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(chardict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m吃\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mGetScode())\n",
      "File \u001b[1;32mc:\\Users\\Takusei\\anaconda3\\Lib\\collections\\__init__.py:1124\u001b[0m, in \u001b[0;36mUserDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__missing__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__missing__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m-> 1124\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '吃'"
     ]
    }
   ],
   "source": [
    "print(chardict[\"吃\"].GetScode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
